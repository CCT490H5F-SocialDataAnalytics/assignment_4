{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - The Social Data of Disasters\n",
    "\n",
    "<table border=\"0\">\n",
    "    <tr>\n",
    "        <td rowspan=\"2\"><img src=\"img/natural-disaster.png\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"img/trump-syria-disaster.png\"></td>\n",
    "        <td><img src=\"img/trump-disaster.png\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Language is pliable. Words can take on different meanings depending on context and who is speaking them. Political speech is no exception. \n",
    "\n",
    "In this assignment, you will be collecting Twitter data on the word 'disaster'. As you can see above, this word takes on many different meanings. In the first, it refers to a natural disaster as reported by a news agency. In the second, it refers to a political disaster by an op-ed columnist. And in the last, it refers to a nebulous, possibly political disaster, but maybe also a social disaster, by (then presidential candidate) Donald Trump.\n",
    "\n",
    "You will first collect some data. Then you will classify whether or not it is political using a tweet classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataFrame():\n",
    "    import glob\n",
    "\n",
    "    tweets = []\n",
    "    files  = list(glob.iglob('assignment4*.json'))\n",
    "    for f in files:\n",
    "        fh = open(f, 'r', encoding = 'utf-8')\n",
    "        tweets_json = fh.read().split(\"\\n\")\n",
    "\n",
    "        ## remove empty lines\n",
    "        tweets_json = list(filter(len, tweets_json))\n",
    "\n",
    "        ## parse each tweet\n",
    "        for tweet in tweets_json:\n",
    "            try:\n",
    "                tweet_obj = json.loads(tweet)\n",
    "\n",
    "                ## copy RT text into text if it exists\n",
    "                if 'retweeted_status' in tweet_obj:\n",
    "                    tweet_obj['text'] = tweet_obj['retweeted_status']['text']\n",
    "\n",
    "                tweets.append(tweet_obj)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    return pd.DataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This imports tweepy. If you haven't installed it on your computer, \n",
    "## try the commands below.\n",
    "try:\n",
    "    import tweepy\n",
    "except ImportError:\n",
    "    !pip install tweepy --prefix=packages\n",
    "    import os\n",
    "    import sys\n",
    "    path = '/packages/Lib/site-packages'\n",
    "    ## If you are running this on Mac, comment out the previous line \n",
    "    ## and uncomment the line below\n",
    "    ##path = '/packages/lib/python3.5/site-packages'\n",
    "    sys.path.insert(0, os.getcwd() + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from slistener import SListener\n",
    "import json\n",
    "import time\n",
    "import tweepy\n",
    "import sys\n",
    "\n",
    "## TODO 1: Enter the authentication tokens which you used in lab.\n",
    "access_token = \"\"\n",
    "access_token_secret = \"\"\n",
    "consumer_key = \"\"\n",
    "consumer_secret = \"\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api  = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## TODO 2: create a list called track which contains the string 'disaster'\n",
    "\n",
    "## TODO 3: set up the listen and stream objects. Pass 'assignment4' as\n",
    "## the second argument to SListener.\n",
    "\n",
    "print(\"Streaming started...\")\n",
    "\n",
    "## Run this cell. \n",
    "## NOTE: let this run until it finishes. It will have collected 200 tweets.\n",
    "## It should take about 10-15 minutes, depending on when you run it.\n",
    "## Go grab a coffee.\n",
    "try:\n",
    "    stream.filter(track = track)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Loads all the tweets. Moves the retweets into main text.\n",
    "df_tweet = createDataFrame()\n",
    "\n",
    "## prints the values of all the tweets\n",
    "df_tweet['text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 4**: Based on the tweets above, give a qualitative description of the tweets. What themes seem to emerge? Are there any surprises?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## TODO 5: create a lowercase text column for text called 'l_text'\n",
    "\n",
    "## TODO 6: detect prescence of word 'trump' in lowercased text. \n",
    "## store in a column called 'trump'\n",
    "\n",
    "df_tweet['class'] = df_tweet['trump'].apply(lambda x: 1 if x >= 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## TODO 7a: Import the TfidfVectorizer module.\n",
    "\n",
    "## TODO 7b: Import the LinearSVC module.\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## This divides the collected tweets into a training and test set.\n",
    "## The split is 80/20 percent, with 80 percent going into the training set and the rest\n",
    "## going into the test set. It is stratified to make sure that enough of each class\n",
    "## gets into the both sets.\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2)\n",
    "train_idx, test_idx = list(sss.split(df_tweet['text'], df_tweet['class']))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Creates a new data frame for each set.\n",
    "df_train = df_tweet.ix[train_idx].copy()\n",
    "df_test  = df_tweet.ix[test_idx].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## TODO 8: Create a TfidfVectorizer named 'vect'\n",
    "\n",
    "X_train = vect.fit_transform(df_train['text'])\n",
    "X_test  = vect.transform(df_test['text'])\n",
    "y_train = df_train['class']\n",
    "y_test  = df_test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## TODO 9: Create a LinearSVC classifier \n",
    "## and train it on X_train and y_train.\n",
    "\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## This prints all the documents labeled as political.\n",
    "df_test[y_pred == 1]['text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 10**: Describe the tweets which have been classified as political. Do all of them contain the word 'Trump'? If so, what can you say about the recall and precision of the classifier. If not, discuss which tweets do not say Trump, and why they may have been classified as political."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
